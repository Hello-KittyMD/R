\documentclass{article}

<<libraries,eval=FALSE,include=FALSE>>=
library(MASS)
library(RColorBrewer)
library(gplots)
library(snowfall)
library(ggplot2)
library(xtable)
library(sandwich)
@

\usepackage{hyperref}
\usepackage{url}
\usepackage{geometry}
\geometry{left=2cm,right=2cm,top=2cm,bottom=2cm}
\renewcommand{\baselinestretch}{1.3}


\begin{document}


\title{Remarks for Lecture 1}
\author{\textbf{Jingwen-Z}\\ Toulouse School of Economics\\ M2 ERNA}
\maketitle

  \section{Library (R)}
    \href{https://cran.r-project.org/web/packages/sandwich/sandwich.pdf}{\textbf{sandwich}}: Model-robust standard error estimators for cross-sectional, time series, and longitudinal data.
    
  \section{Codes}
    \subsection{page 10}
   
<<param,eval=FALSE,results='hide'>>=
# Illustration: to do 
param <- c(8,.5,.28,1500,0.9,0.01,0.05,0.05,0.05,0.1)
names(param) <- c("barmu","sigma2mu","sigma2U","barY","rho","theta","sigma2epsilon","sigma2eta",
                  "delta","baralpha")
@

<<delta.y.tt,eval=FALSE,results='hide'>>=
# Illustration: to do
delta.y.tt <- function(param){
  return(param["baralpha"]+param["theta"]*param["barmu"]-param["theta"]*
           ((param["sigma2mu"]*dnorm((log(param["barY"])-param["barmu"])/
                                       (sqrt(param["sigma2mu"]+param["sigma2U"]))))/
              (sqrt(param["sigma2mu"]+param["sigma2U"])*pnorm((log(param["barY"])-param["barmu"])/
                                                                (sqrt(param["sigma2mu"]+
                                                                        param["sigma2U"]))))))
}
@

<<delta.y.ate,eval=FALSE,results='hide'>>=
# Illustration: to do
delta.y.ate <- function(param){
  return(param["baralpha"]+param["theta"]*param["barmu"])
}
@

<<simul,eval=FALSE,results='hide'>>=
set.seed(1234)
N <-1000
mu <- rnorm(N,param["barmu"],sqrt(param["sigma2mu"]))
UB <- rnorm(N,0,sqrt(param["sigma2U"]))
yB <- mu + UB 
YB <- exp(yB)
Ds <- rep(0,N)
Ds[YB<=param["barY"]] <- 1 
epsilon <- rnorm(N,0,sqrt(param["sigma2epsilon"]))
eta<- rnorm(N,0,sqrt(param["sigma2eta"]))
U0 <- param["rho"]*UB + epsilon
y0 <- mu +  U0 + param["delta"]
alpha <- param["baralpha"]+  param["theta"]*mu + eta
y1 <- y0+alpha
Y0 <- exp(y0)
Y1 <- exp(y1)
y <- y1*Ds+y0*(1-Ds)
Y <- Y1*Ds+Y0*(1-Ds)
@

<<plot.ols.estim.step.0,eval=FALSE,results='hide',fig.cap='Step 0',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
# How Can We Estimate TT Using SO and PFF?-Step 0
col.obs <- 'black'
col.unobs <- 'red'
lty.obs <- 1
lty.unobs <- 2
xlim.big <- c(-1.5,0.5)
xlim.small <- c(-0.15,0.55)
adj <- 0

plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab="yB",ylab="Outcomes")
points(yB[Ds==1],y0[Ds==1],pch=1,col=col.unobs)
abline(v=log(param["barY"]),col=col.unobs)
legend(5,11,c('y0|D=0','y0|D=1'),pch=c(1,1),col=c(col.obs,col.unobs),ncol=1)
@

    \subsection{page 11}

<<ols.reg.0,eval=FALSE,results='hide'>>=
ols.reg.0 <- lm(y[Ds==0]~yB[Ds==0])
summary(ols.reg.0)
@

<<plot.ols.estim.step.1,eval=FALSE,results='hide',fig.cap='Step 1',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
# How Can We Estimate TT Using SO and PFF?-Step 1
plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab="yB",ylab="Outcomes")
points(yB[Ds==1],y0[Ds==1],pch=1,col=col.unobs)
points(yB[Ds==0],ols.reg.0$fitted.values,col='blue')
abline(v=log(param["barY"]),col=col.unobs)
legend(5,11,c('y0|D=0','y0|D=1',expression(hat('y0|D=0'))),pch=c(1,1,1),
       col=c(col.obs,col.unobs,'blue'),ncol=2)
@

    \subsection{page 12}

<<ols.reg.0.pred,eval=FALSE,results='hide'>>=
y.pred <- ols.reg.0$coef[[1]]+ols.reg.0$coef[[2]]*yB[Ds==1]
@

<<plot.ols.estim.step.2,eval=FALSE,results='hide',fig.cap='Step 2',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
# How Can We Estimate TT Using SO and PFF?-Step 2
plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab="yB",ylab="Outcomes")
points(yB[Ds==1],y0[Ds==1],pch=1,col=col.unobs)
points(yB[Ds==0],ols.reg.0$fitted.values,col='blue')
points(yB[Ds==1],y.pred,pch=3,col='blue')
abline(v=log(param["barY"]),col=col.unobs)
legend(5,11,c('y0|D=0','y0|D=1',expression(hat('y0|D=0')),expression(hat('y0|D=1'))),
       pch=c(1,1,1,3),col=c(col.obs,col.unobs,'blue','blue'),ncol=2)
@

    \subsection{page 13}

<<plot.ols.estim.step.3,eval=FALSE,results='hide',fig.cap='Step 3',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
# How Can We Estimate TT Using SO and PFF?-Step 3
plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab="yB",ylab="Outcomes")
points(yB[Ds==1],y0[Ds==1],pch=1,col=col.unobs)
points(yB[Ds==0],ols.reg.0$fitted.values,col='blue')
points(yB[Ds==1],y.pred,col='blue')
points(yB[Ds==1],y[Ds==1],pch=3,col='black')
abline(v=log(param["barY"]),col=col.unobs)
legend(5,11,c('y0|D=0','y0|D=1','y1|D=1',expression(hat('y0|D=0')),expression(hat('y0|D=1'))),
       pch=c(1,1,3,1,3),col=c(col.obs,col.unobs,col.obs,'blue','blue'),ncol=2)
@

    \subsection{page 14}

<<ww.ols,eval=FALSE,results='hide'>>=
ww.ols <- mean(y[Ds==1]-y.pred)
@

<<plot.ols.estim.step.4,eval=FALSE,results='hide',fig.cap='Step 4',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
# How Can We Estimate TT Using SO and PFF?-Step 4
plot(1, type="n", xlab="", ylab="", xlim=xlim.small, ylim=c(0, 10))
abline(v=delta.y.tt(param),col=col.unobs,lty=lty.unobs)
abline(v=ww.ols,col=col.obs,lty=lty.obs)
text(x=c(delta.y.tt(param),ww.ols),y=c(adj),labels=c('TT',expression(hat('E'))),pos=c(4,2),
     col=c(col.unobs,col.obs),lty=c(lty.unobs,lty.obs))
@

    \subsection{page 20}
    
<<ww.ols.direct,eval=FALSE,results='hide'>>=
yB.Ds <-(yB-mean(yB[Ds==1]))*Ds
ols.direct <- lm(y~yB+Ds+yB.Ds)
ww.ols.direct <- ols.direct$coef[[3]]
@

<<plot.ols.estim.direct,eval=FALSE,results='hide',fig.cap='Direct OLS Estimation',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
plot(1, type="n", xlab="", ylab="", xlim=xlim.small, ylim=c(0, 10))
abline(v=delta.y.tt(param),col=col.unobs,lty=lty.unobs)
abline(v=ww.ols.direct,col=col.obs,lty=lty.obs)
text(x=c(delta.y.tt(param),ww.ols.direct),y=c(adj),labels=c('TT',expression(hat('E'))),
     pos=c(4,2),col=c(col.unobs,col.obs),lty=c(lty.unobs,lty.obs))
@

    \subsection{page 23}

<<monte.carlo.ols,eval=FALSE,warning=FALSE,error=FALSE,message=FALSE,results='hide',cache=TRUE>>=
# Illustration: to do
monte.carlo.ols <- function(s,N,param){
  set.seed(s)
  mu <- rnorm(N,param["barmu"],sqrt(param["sigma2mu"]))
  UB <- rnorm(N,0,sqrt(param["sigma2U"]))
  yB <- mu + UB 
  YB <- exp(yB)
  Ds <- rep(0,N)
  Ds[YB<=param["barY"]] <- 1 
  epsilon <- rnorm(N,0,sqrt(param["sigma2epsilon"]))
  eta<- rnorm(N,0,sqrt(param["sigma2eta"]))
  U0 <- param["rho"]*UB + epsilon
  y0 <- mu +  U0 + param["delta"]
  alpha <- param["baralpha"]+  param["theta"]*mu + eta
  y1 <- y0+alpha
  Y0 <- exp(y0)
  Y1 <- exp(y1)
  y <- y1*Ds+y0*(1-Ds)
  Y <- Y1*Ds+Y0*(1-Ds)
  yB.Ds <-(yB-mean(yB[Ds==1]))*Ds
  ols.direct <- lm(y~yB+Ds+yB.Ds)
  ols.simple <- lm(y~yB+Ds)
  return(c(ols.simple$coef[3],ols.direct$coef[3],sqrt(vcov(ols.direct)[3,3]),
           sqrt(vcovHC(ols.direct,type='HC0')[3,3]),sqrt(vcovHC(ols.direct,type='HC1')[3,3]),
           sqrt(vcovHC(ols.direct,type='HC2')[3,3]),sqrt(vcovHC(ols.direct,type='HC3')[3,3])))
}
# library(sandwich) is needed for codes "vcov()"

simuls.ols.N <- function(N,Nsim,param){
  simuls.ols <- matrix(unlist(lapply(1:Nsim,monte.carlo.ols,N=N,param=param)),
                       nrow=Nsim,ncol=7,byrow=TRUE)
  colnames(simuls.ols) <- c('OLS.simple','OLS.direct','Homo','HC0','HC1','HC2','HC3')
  return(simuls.ols)
}

# library(snowfall) is needed for sfInit

sf.simuls.ols.N <- function(N,Nsim,param){
  sfInit(parallel=TRUE,cpus=8)
  sfLibrary(sandwich)
  sim <- matrix(unlist(sfLapply(1:Nsim,monte.carlo.ols,N=N,param=param)),
                nrow=Nsim,ncol=7,byrow=TRUE)
  sfStop()
  colnames(sim) <- c('OLS.simple','OLS.direct','Homo','HC0','HC1','HC2','HC3')
  return(sim)
}

Nsim <- 1000
#Nsim <- 10
N.sample <- c(100,1000,10000,100000)
#N.sample <- c(100,1000,10000)

simuls.ols <- lapply(N.sample,sf.simuls.ols.N,Nsim=Nsim,param=param)
names(simuls.ols) <- N.sample
@

<<monte.carlo.hist.ols,dependson='monte.carlo.ols',eval=FALSE,warning=FALSE,error=FALSE,message=FALSE,results='hide',fig.cap='Distribution of the $OLS$ estimator over replications of samples of different sizes',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
# Sampling Noise with OLS: Illustration
par(mfrow=c(2,2))
for (i in 1:length(simuls.ols)){
  hist(simuls.ols[[i]][,'OLS.direct'],main=paste('N=',as.character(N.sample[i])),
       xlab=expression(hat(Delta^yOLS)),xlim=c(-0.15,0.55))
  abline(v=delta.y.tt(param),col="red")
}
@

    \subsection{page 30}
    
<<precision.ols,dependson='monte.carlo.ols',eval=FALSE,results='hide',warning=FALSE,error=FALSE,message=FALSE,fig.cap='precision of the OLS estimator with 99\\% confidence',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
# Precision of OLS
delta <- 0.99
precision.ols <- function(k){
  return(2*quantile(abs(simuls.ols[[k]][,'OLS.direct']-delta.y.tt(param)),probs=c(delta)))
}
precision.ols.N <- sapply(1:length(simuls.ols),precision.ols)

mean.ols.prec <- function(k,HC,delta=delta){
  return(2*(qnorm((delta+1)/2))*mean(simuls.ols[[k]][,HC]))
}
mean.ols.prec.homo <- sapply(1:length(simuls.ols),mean.ols.prec,HC='Homo',delta=delta)
mean.ols.prec.HC0 <- sapply(1:length(simuls.ols),mean.ols.prec,HC='HC0',delta=delta)
mean.ols.prec.HC1 <- sapply(1:length(simuls.ols),mean.ols.prec,HC='HC1',delta=delta)
mean.ols.prec.HC2 <- sapply(1:length(simuls.ols),mean.ols.prec,HC='HC2',delta=delta)
mean.ols.prec.HC3 <- sapply(1:length(simuls.ols),mean.ols.prec,HC='HC3',delta=delta)

precision.ols <- as.data.frame(cbind(N.sample,precision.ols.N,mean.ols.prec.homo,
                                     mean.ols.prec.HC0,mean.ols.prec.HC1,mean.ols.prec.HC2,
                                     mean.ols.prec.HC3,rep(delta.y.tt(param),length(simuls.ols))))
colnames(precision.ols) <- c('N','precision','Homo','HC0','HC1','HC2','HC3','TT')
# library(ggplot2) should be used here
ggplot(precision.ols, aes(x=as.factor(N), y=TT)) +
  geom_bar(position=position_dodge(), stat="identity", colour='black') +
  geom_errorbar(aes(ymin=TT-precision/2, ymax=TT+precision/2), width=.2,
                position=position_dodge(.9),color='red') +
  geom_errorbar(aes(ymin=TT-Homo/2, ymax=TT+Homo/2), width=.2,
                position=position_dodge(.9),color='blue') +
  geom_errorbar(aes(ymin=TT-HC0/2, ymax=TT+HC0/2), width=.2,
                position=position_dodge(.9),color='green') +
  geom_errorbar(aes(ymin=TT-HC1/2, ymax=TT+HC1/2), width=.2,
                position=position_dodge(.9),color='yellow') +
  geom_errorbar(aes(ymin=TT-HC2/2, ymax=TT+HC2/2), width=.2,
                position=position_dodge(.9),color='orange') +
  geom_errorbar(aes(ymin=TT-HC3/2, ymax=TT+HC3/2), width=.2,
                position=position_dodge(.9),color='purple') +
  xlab("Sample Size") 
@

    \subsection{page 33}

<<param.nonlin,eval=FALSE,results='hide'>>=
# Illustration: to do
param <- c(param,0.1,7.98)
names(param) <- c("barmu","sigma2mu","sigma2U","barY","rho","theta","sigma2epsilon",
                  "sigma2eta","delta","baralpha","gamma","baryB")
@

<<simul.nonlin,eval=FALSE,results='hide'>>=
# Illustration: to do
set.seed(1234)
N <-1000
mu <- rnorm(N,param["barmu"],sqrt(param["sigma2mu"]))
UB <- rnorm(N,0,sqrt(param["sigma2U"]))
yB <- mu + UB 
YB <- exp(yB)
Ds <- rep(0,N)
Ds[YB<=param["barY"]] <- 1 
epsilon <- rnorm(N,0,sqrt(param["sigma2epsilon"]))
eta<- rnorm(N,0,sqrt(param["sigma2eta"]))
U0 <- param["rho"]*UB + epsilon
y0 <- mu +  U0 + param["delta"] + param["gamma"]*(yB-param["baryB"])^2
alpha <- param["baralpha"]+  param["theta"]*mu + eta
y1 <- y0+alpha
Y0 <- exp(y0)
Y1 <- exp(y1)
y <- y1*Ds+y0*(1-Ds)
Y <- Y1*Ds+Y0*(1-Ds)
@

<<plot.nonlin,eval=FALSE,results='hide',fig.cap='Non linear',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
# Nonlinear Relationship Between Outcomes and Confounders-Non linear
plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab="yB",ylab="Outcomes")
points(yB[Ds==1],y0[Ds==1],pch=1,col=col.unobs)
abline(v=log(param["barY"]),col=col.unobs)
legend(5,11,c('y0|D=0','y0|D=1'),pch=c(1,1),col=c(col.obs,col.unobs),ncol=1)
@

    \subsection{page 34}

<<ols.reg.0.nonlin,eval=FALSE,results='hide'>>=
ols.reg.0 <- lm(y[Ds==0]~yB[Ds==0])
summary(ols.reg.0)
@

<<plot.ols.estim.step.1.nonlin,eval=FALSE,results='hide',fig.cap='Step 1',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
# Specification Bias-Step 1
plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab="yB",ylab="Outcomes")
points(yB[Ds==1],y0[Ds==1],pch=1,col=col.unobs)
points(yB[Ds==0],ols.reg.0$fitted.values,col='blue')
abline(v=log(param["barY"]),col=col.unobs)
legend(5,11,c('y0|D=0','y0|D=1',expression(hat('y0|D=0'))),pch=c(1,1,1),
       col=c(col.obs,col.unobs,'blue'),ncol=2)
@

    \subsection{page 35}

<<ols.reg.0.pred.nonlin,eval=FALSE,results='hide'>>=
y.pred <- ols.reg.0$coef[[1]]+ols.reg.0$coef[[2]]*yB[Ds==1]
@

<<plot.ols.estim.step.2.nonlin,eval=FALSE,results='hide',fig.cap='Step 2',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
# Specification Bias-Step 2
plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab="yB",ylab="Outcomes")
points(yB[Ds==1],y0[Ds==1],pch=1,col=col.unobs)
points(yB[Ds==0],ols.reg.0$fitted.values,col='blue')
points(yB[Ds==1],y.pred,pch=3,col='blue')
abline(v=log(param["barY"]),col=col.unobs)
legend(5,11,c('y0|D=0','y0|D=1',expression(hat('y0|D=0')),expression(hat('y0|D=1'))),
       pch=c(1,1,1,3),col=c(col.obs,col.unobs,'blue','blue'),ncol=2)
@

  \subsection{page 36}
  
<<plot.ols.estim.step.3.nonlin,eval=FALSE,results='hide',fig.cap='Step 3',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
# Specification Bias-Step 3
plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab="yB",ylab="Outcomes")
points(yB[Ds==1],y0[Ds==1],pch=1,col=col.unobs)
points(yB[Ds==0],ols.reg.0$fitted.values,col='blue')
points(yB[Ds==1],y.pred,col='blue')
points(yB[Ds==1],y[Ds==1],pch=3,col='black')
abline(v=log(param["barY"]),col=col.unobs)
legend(5,11,c('y0|D=0','y0|D=1','y1|D=1',expression(hat('y0|D=0')),expression(hat('y0|D=1'))),
       pch=c(1,1,3,1,3),col=c(col.obs,col.unobs,col.obs,'blue','blue'),ncol=2)
@

  \subsection{page 37}

<<ww.ols.nonlin,eval=FALSE,results='hide'>>=
ww.ols <- mean(y[Ds==1]-y.pred)
@

<<plot.ols.estim.step.4.nonlin,eval=FALSE,results='hide',fig.cap='Step 4',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
# Specification Bias-Step 3
plot(1, type="n", xlab="", ylab="", xlim=xlim.small, ylim=c(0, 10))
abline(v=delta.y.tt(param),col=col.unobs,lty=lty.unobs)
abline(v=ww.ols,col=col.obs,lty=lty.obs)
text(x=c(delta.y.tt(param),ww.ols),y=c(adj),labels=c('TT',expression(hat('E'))),
     pos=c(4,2),col=c(col.unobs,col.obs),lty=c(lty.unobs,lty.obs))
@

    \subsection{page 41}

<<plot.fail.com.supp,eval=FALSE,results='hide',fig.cap='Failure of Common Support',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
par(mar=c(5,4,4,5))
plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab="yB",ylab="Outcomes")
points(yB[Ds==1],y[Ds==1],pch=3,col='blue')
abline(v=log(param["barY"]),col=col.unobs)
legend(5,10.5,c('y0|D=0','y1|D=1','D'),pch=c(1,3,2),col=c(col.obs,'blue',col.unobs),ncol=1)
par(new=TRUE)
plot(yB,Ds,pch=2,col=col.unobs,xlim=c(5,11),xaxt="n",yaxt="n",xlab="",ylab="")
axis(4)
mtext("D",side=4,line=3)
@

    \subsection{page 43}

<<simul.com.supp,eval=FALSE,results='hide'>>=
# Illustration: to do
set.seed(1234)
mu <- rnorm(N,param["barmu"],sqrt(param["sigma2mu"]))
UB <- rnorm(N,0,sqrt(param["sigma2U"]))
yB <- mu + UB 
YB <- exp(yB)
Ds <- rep(0,N)
V <- rnorm(N,0,sqrt(param["sigma2mu"]+param["sigma2U"]))
Ds[yB+V<=log(param["barY"])] <- 1 
epsilon <- rnorm(N,0,sqrt(param["sigma2epsilon"]))
eta<- rnorm(N,0,sqrt(param["sigma2eta"]))
U0 <- param["rho"]*UB + epsilon
y0 <- mu +  U0 + param["delta"] + param["gamma"]*(yB-param["baryB"])^2
alpha <- param["baralpha"]+  param["theta"]*mu + eta
y1 <- y0+alpha
Y0 <- exp(y0)
Y1 <- exp(y1)
y <- y1*Ds+y0*(1-Ds)
Y <- Y1*Ds+Y0*(1-Ds)
@

<<plot.com.supp,eval=FALSE,results='hide',fig.cap='Common Support Holds',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
par(mar=c(5,4,4,5))
plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab="yB",ylab="Outcomes")
points(yB[Ds==1],y[Ds==1],pch=3,col='blue')
legend(5,10.5,c('y0|D=0','y1|D=1','D'),pch=c(1,3,2),col=c(col.obs,'blue',col.unobs),ncol=1)
par(new=TRUE)
plot(yB,Ds,pch=2,col=col.unobs,xlim=c(5,11),xaxt="n",yaxt="n",xlab="",ylab="")
axis(4)
mtext("D",side=4,line=3)
@

    \subsection{page 54}

<<LLR,eval=FALSE,results='hide',cache=TRUE>>=
# preparation
llr <- function(y,x,gridx,bw,kernel){
  if (kernel=='uniform'){
    K <- function(u){
      K.u <- 0
      if (abs(u)<=.5){K.u <- 1}
      return(K.u)
    }
  }
  if (kernel=='triangular'){
    K <- function(u){
      K.u <- 0
      if (abs(u)<=.5){K.u <- 2*(1-2*abs(u))}
      return(K.u)
    }
  }
  if (kernel=='epanechnikov'){
    K <- function(u){
      K.u <- 0
      if (abs(u)<=.5){K.u <- (3/2)*(1-4*u^2)}
      return(K.u)
    }
  }
  if (kernel=='quartic'){
    K <- function(u){
      K.u <- 0
      if (abs(u)<=.5){K.u <- (15/8)*(1-4*u^2)^2}
      return(K.u)
    }
  }
  if (kernel=='gaussian'){
    K <- function(u){
      return(exp(-0.5*u^2)/(sqrt(2*pi)))
    }
  }
  K.vec <- Vectorize(K)
  y0.hat <- rep(0,length(gridx))  
  for (i in (1:length(gridx))){
    x.i <- gridx[i]-x
    weights.i <- K.vec((x.i)/bw)
    ols.i <- lm(y~x.i,weights=weights.i)
    y0.hat[i] <- ols.i$coefficients[1]
  }
  return(y0.hat)
}

kernel <- 'gaussian'
bw <- 1
y0.llr <- llr(y[Ds==0],yB[Ds==0],yB[Ds==1],bw=bw,kernel=kernel)    
@

<<plot.LLR.step.0,dependson='LLR',eval=FALSE,results='hide',fig.cap='Step 0',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
# LLR Matching-Step 0
plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab="yB",ylab="Outcomes")
points(yB[Ds==1],y0[Ds==1],pch=1,col=col.unobs)
legend(5,11,c('y0|D=0','y0|D=1'),pch=c(1,1),col=c(col.obs,col.unobs),ncol=1)
@

    \subsection{page 55}

<<plot.LLR.step.1,dependson='LLR',eval=FALSE,results='hide',fig.cap='Step 1',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
# LLR Matching-Step 1
plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab="yB",ylab="Outcomes")
points(yB[Ds==1],y0[Ds==1],pch=1,col=col.unobs)
points(yB[Ds==1],y0.llr,col='blue')
legend(5,11,c('y0|D=0','y0|D=1',expression(hat(y0))),pch=c(1,1,1),
       col=c(col.obs,col.unobs,'blue'),ncol=2)
@

    \subsection{page 56}

<<plot.LLR.step.2,dependson='LLR',eval=FALSE,results='hide',fig.cap='Step 2',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
# LLR Matching-Step 2
plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),xlab="yB",ylab="Outcomes")
points(yB[Ds==1],y0[Ds==1],pch=1,col=col.unobs)
points(yB[Ds==1],y0.llr,col='blue')
points(yB[Ds==1],y[Ds==1],pch=3)
legend(5,11,c('y0|D=0','y0|D=1',expression(hat(y0)),'y|D=1'),pch=c(1,1,1,3),
       col=c(col.obs,col.unobs,'blue',col.obs),ncol=2)
@

    \subsection{page 57}

<<ww.llr,dependson='LLR',eval=FALSE,results='hide'>>=
ww.llr <- mean(y[Ds==1]-y0.llr)
@

<<plot.LLR.step.3,dependson='LLR',eval=FALSE,results='hide',fig.cap='Step 3',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
# LLR Matching-Step 3(with bandwidth=1)
plot(1, type="n", xlab="", ylab="", xlim=xlim.small, ylim=c(0, 10))
abline(v=delta.y.tt.com.supp(param),col=col.unobs,lty=lty.unobs)
abline(v=ww.llr,col=col.obs,lty=lty.obs)
text(x=c(delta.y.tt.com.supp(param),ww.llr),y=c(adj),
     labels=c('TT',expression(hat('E'))),
     pos=c(2,4),col=c(col.unobs,col.obs),lty=c(lty.unobs,lty.obs))
@

    \subsection{page 58}

<<llr.matching,eval=FALSE,results='hide',cache=TRUE>>=
llr.match <- function(y,D,x,bw,kernel){
  y0.llr <- llr(y[D==0],x[D==0],x[D==1],bw=bw,kernel=kernel)
  return(mean(y[D==1]-y0.llr))
}
bw <- 0.5
ww.llr.alt <- llr.match(y,Ds,yB,bw=bw,kernel=kernel)
@

<<plot.LLR.step.3.alternate,dependson='llr.matching',eval=FALSE,results='hide',fig.cap='Step 3',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
# LLR Matching-Step 3(with bandwidth=0.5)
plot(1, type="n", xlab="", ylab="", xlim=xlim.small, ylim=c(0, 10))
abline(v=delta.y.tt.com.supp(param),col=col.unobs,lty=lty.unobs)
abline(v=ww.llr.alt,col=col.obs,lty=lty.obs)
text(x=c(delta.y.tt.com.supp(param),ww.llr.alt),y=c(adj),
     labels=c('TT',expression(hat('E'))),
     pos=c(4,2),col=c(col.unobs,col.obs),lty=c(lty.unobs,lty.obs))
@

    \subsection{page 59}

<<LLR.step.1.alt,eval=FALSE,results='hide',cache=TRUE>>=
y0.llr.alt <- llr(y[Ds==0],yB[Ds==0],yB[Ds==1],bw=bw,kernel=kernel)
@

<<plot.LLR.step.1.alt,dependson='LLR.step.1.alt',eval=FALSE,results='hide',fig.cap='Step 1',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
# LLR Matching-Step 1(with bandwidth=0.5)
plot(yB[Ds==0],y0[Ds==0],pch=1,xlim=c(5,11),ylim=c(5,11),
     xlab="yB",ylab="Outcomes")
points(yB[Ds==1],y0[Ds==1],pch=1,col=col.unobs)
points(yB[Ds==1],y0.llr.alt,col='blue')
legend(5,11,c('y0|D=0','y0|D=1',expression(hat(y0))),pch=c(1,1,1),
       col=c(col.obs,col.unobs,'blue'),ncol=2)
@

    \subsection{page 60}

<<monte.carlo.llr,eval=FALSE,warning=FALSE,error=FALSE,message=FALSE,results='hide',cache=TRUE>>=
monte.carlo.llr <- function(s,N,param,bw,kernel){
  set.seed(s)
  mu <- rnorm(N,param["barmu"],sqrt(param["sigma2mu"]))
  UB <- rnorm(N,0,sqrt(param["sigma2U"]))
  yB <- mu + UB 
  YB <- exp(yB)
  Ds <- rep(0,N)
  V <- rnorm(N,0,sqrt(param["sigma2mu"]+param["sigma2U"]))
  Ds[yB+V<=log(param["barY"])] <- 1 
  epsilon <- rnorm(N,0,sqrt(param["sigma2epsilon"]))
  eta<- rnorm(N,0,sqrt(param["sigma2eta"]))
  U0 <- param["rho"]*UB + epsilon
  y0 <- mu +  U0 + param["delta"] + param["gamma"]*(yB-param["baryB"])^2
  alpha <- param["baralpha"]+  param["theta"]*mu + eta
  y1 <- y0+alpha
  Y0 <- exp(y0)
  Y1 <- exp(y1)
  y <- y1*Ds+y0*(1-Ds)
  Y <- Y1*Ds+Y0*(1-Ds)
  ww.llr <- llr.match(y,Ds,yB,bw=bw,kernel=kernel)
  return(ww.llr)
}

simuls.llr.N <- function(N,Nsim,param,bw,kernel){
  simuls.llr <- matrix(unlist(lapply(1:Nsim,monte.carlo.llr,N=N,
                                     param=param,bw=bw,kernel=kernel)),
                       nrow=Nsim,ncol=1,byrow=TRUE)
  colnames(simuls.llr) <- c('LLR')
  return(simuls.llr)
}

sf.simuls.llr.N <- function(N,Nsim,param,bw,kernel){
  sfInit(parallel=TRUE,cpus=8)
  sfExport('llr.match','llr')
  sim.llr <- matrix(unlist(sfLapply(1:Nsim,monte.carlo.llr,N=N,param=param,
                                    bw=bw,kernel=kernel)),nrow=Nsim,ncol=1,byrow=TRUE)
  sfStop()
  colnames(sim.llr) <- c('LLR')
  return(sim.llr)
}

Nsim <- 1000
#Nsim <- 10
#N.sample <- c(100,1000,10000,100000)
#N.sample <- c(100,1000,10000)
N.sample <- c(100,1000)
#simuls.llr <- lapply(N.sample,simuls.llr.N,Nsim=Nsim,param=param,bw=bw,kernel=kernel)
simuls.llr <- lapply(N.sample,sf.simuls.llr.N,Nsim=Nsim,param=param,bw=bw,kernel=kernel)
names(simuls.llr) <- N.sample
@

<<monte.carlo.hist.llr,dependson='monte.carlo.llr',eval=FALSE,warning=FALSE,error=FALSE,message=FALSE,results='hide',fig.cap='Distribution of the $LLR$ estimator over replications of samples of different sizes',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
par(mfrow=c(2,2))
for (i in 1:length(simuls.llr)){
  hist(simuls.llr[[i]][,'LLR'],main=paste('N=',as.character(N.sample[i])),
       xlab=expression(hat(Delta^yLLR)),xlim=c(-0.15,0.55))
  abline(v=delta.y.tt.com.supp(param),col="red")
}
@

    \subsection{page 62}

<<trimming,eval=FALSE,results='hide'>>=
# preparation
# density function estimated at one point
dens.fun.point <- function(n,x,gridx,bw,kernel){
  return(density(x,n=1,from=gridx[n],to=gridx[n],bw=bw,kernel=kernel)[[2]])
}

dens.fun <- function(x,gridx,bw,kernel){
  return(sapply(1:length(gridx), dens.fun.point, x=x, gridx=gridx, bw=bw, kernel=kernel))
}
dens.yB.D0 <- dens.fun(yB[Ds==0],yB[Ds==1],bw=bw.nrd(yB[Ds==0]),kernel='b')
dens.yB.D1 <- dens.fun(yB[Ds==1],yB[Ds==1],bw=bw.nrd(yB[Ds==1]),kernel='b')

com.supp <- function(x,gridx,t,bw,kernel){
  dens.x <- dens.fun(x=x,gridx=gridx,bw=bw,kernel=kernel)
  return(ifelse(dens.x<=quantile(dens.x,t),0,1))
}

t<- 0.05
com.supp.yB <- com.supp(yB[Ds==0],yB[Ds==1],t=t,bw=bw.nrd(yB[Ds==0]),kernel='b')
@

<<plot.trimming,eval=FALSE,results='hide',fig.cap='Trimming and Common Support',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
par(mar=c(5,4,4,5))
plot(yB[Ds==1],dens.yB.D0,pch=1,xlim=c(5,11),ylim=c(0,0.6),xlab="yB",ylab="density")
points(yB[Ds==1],dens.yB.D1,pch=3)
legend(5,0.59,c('fyB|D=0','fyB|D=1','Common Support'),pch=c(1,3,2),
       col=c(col.obs,col.obs,col.unobs),ncol=1)
par(new=TRUE)
plot(yB[Ds==1],com.supp.yB,pch=2,col=col.unobs,xlim=c(5,11),ylim=c(0,1),
     xaxt="n",yaxt="n",xlab="",ylab="")
axis(4)
mtext("Common Support",side=4,line=3)
@

    \subsection{page 63}

<<LLR.trim,eval=FALSE,results='hide',cache=TRUE>>=
#preparation
llr.match.trim <- function(y,D,x,t,bw,kernel){
  com.supp.x <- com.supp(x[D==0],x[D==1],t=t,bw=bw.nrd(x[D==0]),kernel='b')
  y0.llr <- llr(y[D==0],x[D==0],x[D==1][com.supp.x==1],bw=bw,kernel=kernel)
  return(mean(y[D==1][com.supp.x==1]-y0.llr))
}
ww.llr.trim <- llr.match.trim(y,Ds,yB,t=t,bw=bw,kernel=kernel)
@

<<plot.LLR.trimming,dependson='LLR.trim',eval=FALSE,results='hide',fig.cap='LLR Matching with Trimming',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
plot(1, type="n", xlab="", ylab="", xlim=xlim.small, ylim=c(0, 10))
abline(v=delta.y.tt.com.supp(param),col=col.unobs,lty=lty.unobs)
abline(v=ww.llr.trim,col=col.obs,lty=lty.obs)
text(x=c(delta.y.tt.com.supp(param),ww.llr.trim),y=c(adj),
     labels=c('TT',expression(hat('E'))),pos=c(4,2),col=c(col.unobs,col.obs),
     lty=c(lty.unobs,lty.obs))
@

    \subsection{page 64}
<<monte.carlo.llr.trim,eval=FALSE,warning=FALSE,error=FALSE,message=FALSE,results='hide',cache=TRUE>>=
monte.carlo.llr.trim <- function(s,N,param,t,bw,kernel){
  set.seed(s)
  mu <- rnorm(N,param["barmu"],sqrt(param["sigma2mu"]))
  UB <- rnorm(N,0,sqrt(param["sigma2U"]))
  yB <- mu + UB 
  YB <- exp(yB)
  Ds <- rep(0,N)
  V <- rnorm(N,0,sqrt(param["sigma2mu"]+param["sigma2U"]))
  Ds[yB+V<=log(param["barY"])] <- 1 
  epsilon <- rnorm(N,0,sqrt(param["sigma2epsilon"]))
  eta<- rnorm(N,0,sqrt(param["sigma2eta"]))
  U0 <- param["rho"]*UB + epsilon
  y0 <- mu +  U0 + param["delta"] + param["gamma"]*(yB-param["baryB"])^2
  alpha <- param["baralpha"]+  param["theta"]*mu + eta
  y1 <- y0+alpha
  Y0 <- exp(y0)
  Y1 <- exp(y1)
  y <- y1*Ds+y0*(1-Ds)
  Y <- Y1*Ds+Y0*(1-Ds)
  ww.llr <- llr.match.trim(y,Ds,yB,t=t,bw=bw,kernel=kernel)
  return(ww.llr)
}

simuls.llr.trim.N <- function(N,Nsim,param,t,bw,kernel){
  simuls.llr.trim <- matrix(unlist(lapply(1:Nsim,monte.carlo.llr.trim,
                                          N=N,param=param,t=t,bw=bw,kernel=kernel)),
                            nrow=Nsim,ncol=1,byrow=TRUE)
  colnames(simuls.llr.trim) <- c('LLR Trim')
  return(simuls.llr.trim)
}

sf.simuls.llr.trim.N <- function(N,Nsim,param,t,bw,kernel){
  sfInit(parallel=TRUE,cpus=8)
  sfExport('llr.match.trim','llr','dens.fun.point','dens.fun','com.supp')
  sim.llr.trim <- matrix(unlist(sfLapply(1:Nsim,monte.carlo.llr.trim,
                                         N=N,param=param,t=t,bw=bw,kernel=kernel)),
                         nrow=Nsim,ncol=1,byrow=TRUE)
  sfStop()
  colnames(sim.llr.trim) <- c('LLR Trim')
  return(sim.llr.trim)
}

Nsim <- 1000
#Nsim <- 10
#N.sample <- c(100,1000,10000,100000)
#N.sample <- c(100,1000,10000)
N.sample <- c(100)
#simuls.llr.trim <- lapply(N.sample,simuls.llr.trim.N,Nsim=Nsim,
#                         param=param,t=t,bw=bw,kernel=kernel)
simuls.llr.trim <- lapply(N.sample,sf.simuls.llr.trim.N,Nsim=Nsim,
                          param=param,t=t,bw=bw,kernel=kernel)
names(simuls.llr.trim) <- N.sample
@

<<monte.carlo.hist.llr.trim,dependson='monte.carlo.llr.trim',eval=FALSE,warning=FALSE,error=FALSE,message=FALSE,results='hide',fig.cap='Distribution of the trimmed $LLR$ estimator over replications of samples of different sizes',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
par(mfrow=c(2,2))
for (i in 1:length(simuls.llr.trim)){
  hist(simuls.llr.trim[[i]][,'LLR Trim'],main=paste('N=',as.character(N.sample[i])),
       xlab=expression(hat(Delta^yLLRTrim)),xlim=c(-0.15,0.55))
  abline(v=delta.y.tt.com.supp(param),col="red")
}
@

    \subsection{page 66}

<<llr.bw.cv,eval=FALSE,results='hide',cache=TRUE>>=
# prepa
MSE.llr <- function(bw,y,D,x,kernel){
  MSE <- 0
  for (i in (1:length(y[D==0]))){
    MSE <- MSE + (y[D==0][i]-llr(y[D==0][-i],x[D==0][-i],x[D==0][i],bw=bw,kernel=kernel))^2
  }
  return(MSE)
}
MSE.test <- MSE.llr(bw=1,y,Ds,yB,kernel='gaussian')
MSE.grid <- seq(0.1,1,by=.1)
MSE.grid.test <- sapply(MSE.grid,MSE.llr,y=y,D=Ds,x=yB,kernel='gaussian')

#sfInit(parallel=TRUE,cpus=8)
#sfExport('llr.match.trim','llr','dens.fun.point','dens.fun','com.supp','MSE.llr')
#MSE.grid.test <- sfSapply(MSE.grid,MSE.llr,y=y,D=Ds,x=yB,kernel='gaussian')
#sfStop()
@

<<plot.LLR.CV,dependson='llr.bw.cv',eval=FALSE,results='hide',fig.cap='MSE as a function of Bandwidth for LLR in the untreated sample',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
plot(MSE.grid[2:10],MSE.grid.test[2:10], xlab="Bandwidth", ylab="MSE")
@

    \subsection{page 71}

<<prop.score,eval=FALSE,results='hide'>>=
probit.Ds <- glm(Ds~yB, family=binomial(link="probit"))
pscore <- predict(probit.Ds,type="response")
@

<<plot.pscore,eval=FALSE,results='hide',fig.cap='Propensity score as a function of yB',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
plot(yB,pscore, xlab="yB", ylab="Propensity score")
@

    \subsection{page 72}

<<plot.pscore.y,eval=FALSE,results='hide',fig.cap='Propensity score and outcomes',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
plot(pscore[Ds==0],y[Ds==0], ylab="Outcomes", xlab="Propensity score",
     xlim=c(0,1),ylim=c(5,11))
points(pscore[Ds==1],y[Ds==1],pch=3,col='blue')
points(pscore[Ds==1],y0[Ds==1],pch=1,col=col.unobs)
legend(0.7,11,c('y0|D=0','y1|D=1','y0|D=1'),pch=c(1,3,1),
       col=c(col.obs,'blue',col.unobs),ncol=1)
@

    \subsection{page 73}

<<LLR.trim.pscore,eval=FALSE,results='hide',cache=TRUE>>=
MSE.grid.pscore <- seq(0.02,0.1,by=.02)
MSE.pscore <- sapply(MSE.grid.pscore,MSE.llr,y=y,D=Ds,x=pscore,kernel='gaussian')
bw <- MSE.grid.pscore[MSE.pscore==min(MSE.pscore)]
ww.llr.trim.pscore <- llr.match.trim(y,Ds,pscore,t=t,bw=bw,kernel=kernel)
@

<<plot.LLR.trimming.pscore,dependson='LLR.trim.pscore',eval=FALSE,results='hide',fig.cap='LLR Matching on the Propensity Score',fig.align='center',out.width='.65\\textwidth',fig.pos='htbp'>>=
plot(1, type="n", xlab="", ylab="", xlim=xlim.small, ylim=c(0, 10))
abline(v=delta.y.tt.com.supp(param),col=col.unobs,lty=lty.unobs)
abline(v=ww.llr.trim.pscore,col=col.obs,lty=lty.obs)
text(x=c(delta.y.tt.com.supp(param),ww.llr.trim.pscore),y=c(adj),
     labels=c('TT',expression(hat('E'))),pos=c(4,2),col=c(col.unobs,col.obs),
     lty=c(lty.unobs,lty.obs))
@

  \section{Key notions}
Here is a set of stuff that I would find useful to do:

\begin{enumerate}
  \item Compute the OLS estimators (step by step and direct) and compare their values with the theoretical TT.
  \item Compute the robust standard errors and sampling noise.
  \item Compute the LLR estimator on the sample with common support. For that, 
  1) estimate the propensity score; 2)common support and trimming; 3)LLR matching on the trimmed sample
  \item Compute the standard errors and sampling noise using the bootstrap.
\end{enumerate}

\noindent{\textbf{Bonus:}}

\begin{enumerate}
  \item What happens when the variance of the Vi error term decreases? Does the impact of trimming become clearer?
  \item Use on of the other matching estimators and compute estimated TT and sampling noise. Compare with LLR Matching.
  \item Use the formula for the semiparametric efficiency bound to estimate sampling noise. Is it close to the bootstrap result?
  \item Use the bootstrap for Nearest Neighbor: is the resulting estimate of sampling noise different from the one returned by the Abadie and Imbens s.e.? By the bootstrap for LLR? By the efficiency bound?
\end{enumerate}


\end{document}
